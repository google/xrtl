#!/usr/bin/env python

# Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Build script for XRTL.
This provides build, test, linting, and other utilities based on bazel.
All commands can be executed manually but are easier through this (in most
cases).
"""


import argparse
import difflib
import fnmatch
import hashlib
import json
import os
import re
import shutil
import string
import subprocess
import sys


self_path = os.path.dirname(os.path.abspath(__file__))


# Default config for the current host OS.
if (sys.platform == 'cygwin' or
    sys.platform == 'win32'):
  default_config = 'windows_x86_64'
elif sys.platform == 'darwin':
  default_config = 'macos_x86_64'
else:
  default_config = ''


top_level_packages = [
    '//xrtl/base/...',
    '//xrtl/examples/...',
    '//xrtl/gfx/...',
    '//xrtl/testing/...',
    '//xrtl/tools/...',
    '//xrtl/ui/...',
    ]


def main():
  # Add self to the root search path.
  sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

  # Check python version.
  if not sys.version_info[:2] == (2, 7):
    print('ERROR: Python 2.7 must be installed and on PATH')
    return 1

  # Check git exists.
  if not has_bin('git'):
    print('ERROR: git must be installed and on PATH.')
    return 1

  # Check bazel exists.
  if not has_bin('bazel'):
    print('ERROR: bazel must be installed and on PATH.')
    return 1

  # Grab Visual Studio version and execute shell to set up environment.
  if sys.platform in ('cygwin', 'win32'):
    vs_version = import_vs_environment()
    if vs_version != 2017:
      print('ERROR: Visual Studio 2017 not found!')
      return 1

  # Setup main argument parser and common arguments.
  parser = argparse.ArgumentParser(prog='xtool')

  # Grab all commands and populate the argument parser for each.
  subparsers = parser.add_subparsers(title='subcommands',
                                     dest='subcommand')
  commands = discover_commands(subparsers)

  # If the user passed no args, die nicely.
  if len(sys.argv) == 1:
    parser.print_help()
    return 1

  # Gather any arguments that we want to pass to child processes.
  command_args = sys.argv[1:]
  pass_args = []
  try:
    pass_index = command_args.index('--')
    pass_args = command_args[pass_index + 1:]
    command_args = command_args[:pass_index]
  except:
    pass

  # Special case for bazel commands. This lets us pass everything we don't
  # understand right to bazel.
  allow_unknown_args = False
  if len(command_args) and command_args[0] in ('clean', 'build', 'run', 'test',
                                               'query', 'info', 'sln'):
    allow_unknown_args = True

  # Parse command name and dispatch.
  if allow_unknown_args:
    (known_args, unknown_args) = parser.parse_known_args(command_args)
    args = vars(known_args)
    pass_args = unknown_args + ['--'] + pass_args
  else:
    args = vars(parser.parse_args(command_args))
  command_name = args['subcommand']
  try:
    command = commands[command_name]
    return_code = command.execute(args, pass_args, os.getcwd())
  except Exception as e:
    raise
    return_code = 1
  return return_code


def query_reg_sz(key, value):
  reg_binary = 'reg.exe'
  p = subprocess.Popen([
      reg_binary,
      'query',
      key,
      '/v',
      value,
      ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  (stdout, stderr) = p.communicate()
  if not stderr:
    for line in stdout.split('\n'):
      line = line.strip()
      if line.startswith(value) and line.find('REG_SZ') != -1:
        return line[line.find('REG_SZ') + len('REG_SZ'):].strip()
  return None


def import_vs_environment():
  """Finds the installed Visual Studio version and imports
  interesting environment variables into os.environ.

  Returns:
    A version such as 2017 or None if no VS is found.
  """

  # Pull the current paths, if specified. We'll use this to override our
  # detection.
  if 'BAZEL_VS' in os.environ and not 'BAZEL_VC' in os.environ:
    os.environ['BAZEL_VC'] = os.environ['BAZEL_VS'] + "\\VC\\"
  bazel_vc = os.environ.get('BAZEL_VC', '')

  if not bazel_vc:
    # Query first for VC++ tools, as we want to support non-VS installs. If it's
    # not found we'll fall back to the VS directory.
    vc7_dir = query_reg_sz(
        'HKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Microsoft\\VisualStudio\\SxS\\VC7',
        '15.0')
    vs7_dir = query_reg_sz(
        'HKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Microsoft\\VisualStudio\\SxS\\VS7',
        '15.0')
    if vc7_dir and os.path.exists(vc7_dir):
      bazel_vc = vc7_dir
    elif vs7_dir and os.path.exists(vs7_dir):
      bazel_vc = os.path.join(vs7_dir, 'VC')
    os.environ['BAZEL_VC'] = bazel_vc

  if not bazel_vc:
    # Couldn't find any kind of VC++/VS install.
    return None

  vcvarsall_path = os.path.join(bazel_vc, 'Auxiliary\\Build\\vcvarsall.bat')
  if not os.path.exists(vcvarsall_path):
    print('ERROR: BAZEL_VC set to %s but no vcvarsall.bat found' % (bazel_vc))
    return None

  if sys.platform == 'cygwin':
    args = ['tools\\/utils\\/echo_vcvarsall.bat']
    envvars_to_save = (
        'devenvdir',
        'include',
        'lib',
        'libpath',
        'pathext',
        'systemroot',
        'vcinstalldir',
        'windowssdkdir',
        )
  else:
    args = [vcvarsall_path, 'x64', '&&', 'set']
    envvars_to_save = (
        'devenvdir',
        'include',
        'lib',
        'libpath',
        'path',
        'pathext',
        'systemroot',
        'temp',
        'tmp',
        'vcinstalldir',
        'visualstudioversion',
        'windowssdkdir',
        )
  popen = subprocess.Popen(
      args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
  variables, _ = popen.communicate()
  for line in variables.splitlines():
    for envvar in envvars_to_save:
      if re.match(envvar + '=', line.lower()):
        var, setting = line.split('=', 1)
        if envvar == 'path':
          setting = os.path.dirname(sys.executable) + os.pathsep + setting
        os.environ[var.upper()] = setting
        break

  version = 0
  if os.environ.get('VISUALSTUDIOVERSION', '') == '15.0':
    version = 2017

  os.environ['VSVERSION'] = str(version)
  return version


def format_uuid(uuid):
  """Formats a dense hex UUID string into a dashed format.

  Args:
    uuid: input UUID as 'E90AFB8EA87B3B38903DC0A5B0928FDF'.

  Returns:
    UUID with dashes as 'E90AFB8E-A87B-3B38-903D-C0A5B0928FDF'.
  """
  return '%s-%s-%s-%s-%s' % (uuid[0:8], uuid[8:12], uuid[12:16], uuid[16:20],
                             uuid[20:32])


def convert_path_cygwin_to_win32(cygwin_path):
  """Converts a /cygdrive/c/foo path to a C:\\foo path.
  No-op on non-cygwin platforms.

  Args:
    cygwin_path: file path in cygwin format.

  Returns:
    File path in win32 format.
  """
  # On Windows we want a Windows path (C:\foo). Convert here if
  # we are under cygwin.
  if sys.platform == 'cygwin' and cygwin_path.startswith('/'):
    windows_path = cygwin_path.replace('/cygdrive/', '')
    drive_name = '%s:\\\\' % (windows_path[0:1])
    windows_path = windows_path[2:].replace('/', '\\\\')
    windows_path = '%s%s' % (drive_name, windows_path)
  elif sys.platform == 'cygwin' or sys.platform == 'win32':
    windows_path = cygwin_path.replace('/', '\\')
  else:
    windows_path = cygwin_path
  return windows_path


def has_bin(bin):
  """Checks whether the given binary is present.

  Args:
    bin: binary name (without .exe, etc).
  Returns:
    True if the binary exists.
  """
  bin_path = get_bin(bin)
  if not bin_path:
    return False
  return True


def get_bin(bin):
  """Checks whether the given binary is present and returns the path.

  Args:
    bin: binary name (without .exe, etc).
  Returns:
    Full path to the binary or None if not found.
  """
  for path in os.environ['PATH'].split(os.pathsep):
    path = path.strip('"')
    exe_file = os.path.join(path, bin)
    if os.path.isfile(exe_file) and os.access(exe_file, os.X_OK):
      return exe_file
    exe_file = exe_file + '.exe'
    if os.path.isfile(exe_file) and os.access(exe_file, os.X_OK):
      return exe_file
  return None


def shell_call(command, throw_on_error=True, stdout_path=None):
  """Executes a shell command.

  Args:
    command: Command to execute, as a list of parameters.
    throw_on_error: Whether to throw an error or return the status code.
    stdout_path: File path to write stdout output to.
  Returns:
    If throw_on_error is False the status code of the call will be returned.
  """
  stdout_file = None
  if stdout_path:
    stdout_file = open(stdout_path, 'w')
  result = 0
  try:
    if throw_on_error:
      result = 1
      subprocess.check_call(command, shell=False, stdout=stdout_file)
      result = 0
    else:
      result = subprocess.call(command, shell=False, stdout=stdout_file)
  finally:
    if stdout_file:
      stdout_file.close()
  return result


def _prepare_bazel_environ():
  """Ensures bazel environment variables are set.

  This is not required but ensures the tools used by bazel match the ones we
  select and also quiets bazel warnings about them being autoconfigured.
  """
  if 'BAZEL_SH' not in os.environ:
    os.environ['BAZEL_SH'] = get_bin('bash')
  if 'BAZEL_PYTHON' not in os.environ:
    os.environ['BAZEL_PYTHON'] = get_python_binary()
  if 'BAZEL_VC' not in os.environ and 'VCINSTALLDIR' in os.environ:
    os.environ['BAZEL_VC'] = os.environ['VCINSTALLDIR']


def invoke_bazel(command, args, output_base = None):
  """Invokes a bazel command.

  Args:
    command: the bazel command, such as 'build'.
    args: a list of arguments to pass to bazel.
    output_base: absolute path to dump bazel outputs.

  Returns:
    Exit value of bazel, 0 is success.
  """
  _prepare_bazel_environ()
  run_args = ['bazel']
  run_args.append('--bazelrc=' + os.path.join(self_path, 'tools/bazel.rc'))
  if output_base:
    run_args.append('--output_base=%s' % (output_base))
  run_args.append(command)
  run_args.extend(args)
  return subprocess.call(run_args, shell=False)


def bazel_info(key, config = default_config, output_base = None):
  """Gets a bazel info value.

  Args:
    key: bazel info key.
    config: --config value (or platform default is unspecified).
    output_base: absolute path to dump bazel outputs.

  Returns:
    Key value.
  """
  # Memoize the lookup.
  if not hasattr(bazel_info, 'cache'):
    bazel_info.cache = {}
  cache_key = '%s-%s' % (key, config)
  if cache_key in bazel_info.cache:
    return bazel_info.cache[cache_key]

  _prepare_bazel_environ()
  value = subprocess.check_output([
      'bazel',
      ] + (['--output_base=%s' % (output_base),] if output_base else []) + [
      'info',
      '--config=%s' % (config),
      key,
      ], cwd=self_path).decode('utf-8').rstrip()

  # Add to cache.
  bazel_info.cache[cache_key] = value
  return value


def get_git_head_info():
  """Queries the current branch and commit checksum from git.

  Returns:
    (branch_name, commit, commit_short)
    If the user is not on any branch the name will be 'detached'.
  """
  p = subprocess.Popen([
      'git',
      'symbolic-ref',
      '--short',
      '-q',
      'HEAD',
      ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  (stdout, stderr) = p.communicate()
  branch_name = stdout.strip() or 'detached'
  p = subprocess.Popen([
      'git',
      'rev-parse',
      'HEAD',
      ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  (stdout, stderr) = p.communicate()
  commit = stdout.strip() or 'unknown'
  p = subprocess.Popen([
      'git',
      'rev-parse',
      '--short',
      'HEAD',
      ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  (stdout, stderr) = p.communicate()
  commit_short = stdout.strip() or 'unknown'
  return (branch_name, commit, commit_short)


def git_submodule_update():
  """Runs a full recursive git submodule init and update.
  """
  shell_call([
      'git',
      'submodule',
      'update',
      '--init',
      '--recursive',
      ])


def get_python_binary():
  """Finds the python binary. Aborts if none is found.

  Returns:
    A path to the python binary. This may differ from sys.executable.
  """
  python_exe = get_bin('python.exe')
  if not python_exe:
    python_exe = get_bin('python')
  if not python_exe:
    python_exe = sys.executable
  python_exe = convert_path_cygwin_to_win32(python_exe)
  return python_exe


def get_clang_format_binary():
  """Finds a clang-format binary. Aborts if none is found.

  Returns:
    A path to the clang-format executable.
  """
  attempts = [
      'C:\\Program Files\\LLVM\\bin\\clang-format.exe',
      'C:\\Program Files (x86)\\LLVM\\bin\\clang-format.exe',
      'clang-format-4.0',
      'clang-format',
      ]
  for binary in attempts:
    if has_bin(binary):
      return binary
  print 'ERROR: clang-format is not on PATH'
  print 'LLVM is available from http://llvm.org/releases/download.html'
  print 'At least version 4.0 is required.'
  sys.exit(1)


def get_git_clang_format_py():
  """Finds the git-clang-format python file. Aborts if none is found.

  Returns:
    A path to the git-clang-format executable.
  """
  attempts = [
      'C:\\Program Files\\LLVM\\bin\\git-clang-format',
      'C:\\Program Files (x86)\\LLVM\\bin\\git-clang-format',
      'git-clang-format-4.0',
      'git-clang-format',
      ]
  for py_path in attempts:
    if has_bin(py_path):
      return get_bin(py_path)
  print 'ERROR: git-clang-format is not on PATH'
  print 'LLVM is available from http://llvm.org/releases/download.html'
  print 'At least version 4.0 is required.'
  sys.exit(1)


def get_clang_tidy_binary():
  """Finds a clang-tidy binary.

  Returns:
    A path to the clang-tidy executable or empty string if not found.
  """
  attempts = [
      'C:\\Program Files\\LLVM\\bin\\clang-tidy.exe',
      'C:\\Program Files (x86)\\LLVM\\bin\\clang-tidy.exe',
      'clang-tidy-4.0',
      'clang-tidy',
      ]
  for binary in attempts:
    if has_bin(binary):
      return binary
  print 'ERROR: clang-tidy is not on PATH'
  print 'LLVM is available from http://llvm.org/releases/download.html'
  print 'At least version 4.0 is required.'
  sys.exit(1)


def write_if_changed(path, contents):
  """Writes file contents if they are different than what exists at the path.

  This is useful for files that may be watched by other processes (such as
  Visual Studio).

  Args:
    path: file path.
    contents: file contents str.
  """
  if os.path.exists(path):
    # File exists - load contents and compare.
    try:
      with open(path, 'r') as file:
        existing_contents = file.read()
      if unicode(contents) == unicode(existing_contents):
        # Contents are the same.
        return
    except: pass
  with open(path, 'w') as file:
    file.write(contents)


def discover_commands(subparsers):
  """Looks for all commands and returns a dictionary of them.
  In the future commands could be discovered on disk.

  Args:
    subparsers: Argument subparsers parent used to add command parsers.
  Returns:
    A dictionary containing name-to-Command mappings.
  """
  commands = {
      'setup': SetupCommand(subparsers),
      'pull': PullCommand(subparsers),
      'clean': CleanCommand(subparsers),
      'build': BuildCommand(subparsers),
      'run': RunCommand(subparsers),
      'test': TestCommand(subparsers),
      'query': QueryCommand(subparsers),
      'info': InfoCommand(subparsers),
      'lint': LintCommand(subparsers),
      'fix': FixCommand(subparsers),
      'tidy': TidyCommand(subparsers),
      'presubmit': PresubmitCommand(subparsers),
      }
  if sys.platform in ('cygwin', 'win32'):
    commands['sln'] = GenerateSlnCommand(subparsers)
  return commands


class Command(object):
  """Base type for commands.
  """

  def __init__(self, subparsers, name, help_short=None, help_long=None,
               *args, **kwargs):
    """Initializes a command.

    Args:
      subparsers: Argument subparsers parent used to add command parsers.
      name: The name of the command exposed to the management script.
      help_short: Help text printed alongside the command when queried.
      help_long: Extended help text when viewing command help.
    """
    self.name = name
    self.help_short = help_short
    self.help_long = help_long

    if subparsers:
      self.parser = subparsers.add_parser(name,
                                          help=help_short,
                                          description=help_long)
      self.parser.set_defaults(command_handler=self)
    else:
      self.parser = None

  def execute(self, args, pass_args, cwd):
    """Executes the command.

    Args:
      args: Arguments hash for the command.
      pass_args: Arguments list to pass to child commands.
      cwd: Current working directory.
    Returns:
      Return code of the command.
    """
    return 1


class SetupCommand(Command):
  """'setup' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(SetupCommand, self).__init__(
        subparsers,
        name='setup',
        help_short='Setup the build environment.',
        *args, **kwargs)

  def execute(self, args, pass_args, cwd):
    print('Setting up the build environment...')
    print('')

    # Setup submodules.
    print('- git submodule init / update...')
    git_submodule_update()
    print('')

    # Install required python modules.
    python_modules = []
    try:
      from google.protobuf import message
    except:
      python_modules.append('protobuf')
    if python_modules:
      return_code = 1
      if has_bin('pip'):
        print('- pip install %s' % (' '.join(python_modules)))
        return_code = shell_call([
            'pip',
            'install',
            ] + python_modules)
      elif has_bin('easy_install'):
        print('- easy_install %s' % (' '.join(python_modules)))
        return_code = shell_call([
            'easy_install',
            ] + python_modules)
      if return_code:
        print('ERROR: pip and easy_install not found or an error occurred!')
        print('You\'ll need to install the following python modules:')
        for python_module in python_modules:
          print('  %s' % (python_module))
        return return_code
      print('')

    # Install required go dependencies.
    go_packages = [
        'github.com/bazelbuild/buildtools/buildifier',
        ]
    if go_packages:
      if has_bin('go'):
        print('- go get %s' % (' '.join(go_packages)))
        return_code = shell_call([
            'go',
            'get',
            ] + go_packages)
      else:
        return_code = 1
      if return_code:
        print('ERROR: go not found or an error occurred!')
        print('Ensure you have go installed and on your path.')
        print('You\'ll need to install the following go packages:')
        for go_package in go_packages:
          print('  %s' % (go_package))
        return 1

    return 0


class PullCommand(Command):
  """'pull' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(PullCommand, self).__init__(
        subparsers,
        name='pull',
        help_short='Pulls the repo and all dependencies and rebases changes.',
        *args, **kwargs)
    self.parser.add_argument('--merge', action='store_true',
                             help='Merges on master instead of rebasing.')

  def execute(self, args, pass_args, cwd):
    print('Pulling...')
    print('')

    print('- switching to master...')
    shell_call([
        'git',
        'checkout',
        'master',
        ])
    print('')

    print('- pulling self...')
    if args['merge']:
      shell_call([
          'git',
          'pull',
          ])
    else:
      shell_call([
          'git',
          'pull',
          '--rebase',
          ])
    print('')

    print('- pulling dependencies...')
    git_submodule_update()
    print('')

    # TODO(benvanik): run tulsi/sln/etc.

    return 0


class BazelCommand(Command):
  """Base for commands that invoke bazel."""

  def __init__(self, subparsers, *args, **kwargs):
    super(BazelCommand, self).__init__(
        subparsers,
        *args, **kwargs)
    self.parser.add_argument(
        '--output_base',
        help='Write bazel outputs to the given path.')
    self.parser.add_argument(
        '--all', action='store_true',
        help='Performs the bazel action on all top-level packages.')

  def execute(self, args, bazel_command, pass_args, cwd):
    # Add --config set to default if none was specified.
    has_config = False
    for arg in pass_args:
      if arg.startswith('--config='):
        has_config = True
        break
    if not has_config:
      pass_args = ['--config=%s' % (default_config)] + pass_args
    if args['all']:
      pass_args += top_level_packages

    result = invoke_bazel(bazel_command, pass_args,
                          output_base = args['output_base'])
    print('')
    if result != 0:
      print('ERROR: build failed with one or more errors.')
      return result
    return 0


class CleanCommand(BazelCommand):
  """'clean' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(CleanCommand, self).__init__(
        subparsers,
        name='clean',
        help_short='Runs a bazel clean.',
        *args, **kwargs)

  def execute(self, args, pass_args, cwd):
    # TODO(benvanik): build script.
    result = super(CleanCommand, self).execute(args, 'clean', pass_args, cwd)
    if not result:
      print('Success!')
    return result


class BuildCommand(BazelCommand):
  """'build' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(BuildCommand, self).__init__(
        subparsers,
        name='build',
        help_short='Runs a bazel build.',
        *args, **kwargs)

  def execute(self, args, pass_args, cwd):
    # TODO(benvanik): build script.
    result = super(BuildCommand, self).execute(args, 'build', pass_args, cwd)
    if not result:
      print('Success!')
    return result


class RunCommand(BazelCommand):
  """'run' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(RunCommand, self).__init__(
        subparsers,
        name='run',
        help_short='Runs tests for several platforms at once.',
        help_long='''
        To pass arguments to the executables separate them with `--`.
          $ xtool run //:target -- --some_test_arg
        ''',
        *args, **kwargs)
    # TODO(benvanik): configs for platforms to run tests on.

  def execute(self, args, pass_args, cwd):
    # TODO(benvanik): run script.
    result = super(RunCommand, self).execute(args, 'run', pass_args, cwd)
    if not result:
      print('Success!')
    return result


class TestCommand(BazelCommand):
  """'test' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(TestCommand, self).__init__(
        subparsers,
        name='test',
        help_short='Runs a bazel test.',
        *args, **kwargs)

  def execute(self, args, pass_args, cwd):
    # TODO(benvanik): test script.
    result = super(TestCommand, self).execute(args, 'test', pass_args, cwd)
    if not result:
      print('Success!')
    return result


class QueryCommand(BazelCommand):
  """'query' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(QueryCommand, self).__init__(
        subparsers,
        name='query',
        help_short='Issues a bazel query.',
        *args, **kwargs)

  def execute(self, args, pass_args, cwd):
    result = super(QueryCommand, self).execute(args, 'query', pass_args, cwd)
    if not result:
      print('Success!')
    return result


class InfoCommand(BazelCommand):
  """'info' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(InfoCommand, self).__init__(
        subparsers,
        name='info',
        help_short='Issues a bazel info.',
        *args, **kwargs)

  def execute(self, args, pass_args, cwd):
    result = super(InfoCommand, self).execute(args, 'info', pass_args, cwd)
    return result


def is_bazel_file(file_path):
  """
  Args:
    file_path: file path (like '.../foo.bzl').

  Returns:
    True if the file is considered a bazel BUILD/etc file.
  """
  return file_path.endswith((
      'BUILD',
      '.bzl',
      ))


def is_source_file(file_path):
  """
  Args:
    file_path: file path (like '.../foo.cc').

  Returns:
    True if the file is considered a source file.
  """
  return file_path.endswith((
      '.cc',
      '.c',
      '.h',
      '.inl',
      '.mm',
      '.m',
      '.java',
      '.py',
      ))


def find_xrtl_source_files(file_filter = is_source_file):
  """Gets all XRTL source files in the project.

  Args:
    file_filter: function that returns true if the file should be included.

  Returns:
    A list of file paths.
  """
  all_files = [os.path.join(root, name)
      for root, dirs, files in os.walk('xrtl')
      for name in files
      if file_filter(name)]
  return [file_path.replace('\\', '/') for file_path in all_files]


def find_all_source_files(file_filter = is_source_file):
  """Gets all interesting source files in the project.

  Args:
    file_filter: function that returns true if the file should be included.

  Returns:
    A list of file paths.
  """
  return find_xrtl_source_files(file_filter)


def find_changed_source_files(file_filter = is_source_file, diff_origin = False):
  """Gets all changed source files from the origin.

  Args:
    diff_origin: git diff against origin/master, not HEAD.
    file_filter: function that returns true if the file should be included.

  Returns:
    A list of file paths.
  """
  p = subprocess.Popen([
      'git',
      'diff',
      '--name-only',
      '%s' % ('origin/master' if diff_origin else 'HEAD')
      ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  (stdout, stderr) = p.communicate()
  changed_files = stdout.strip().split('\n')
  changed_files = [file_path
                   for file_path in changed_files
                   if file_filter(file_path)]
  return changed_files


def lint_check_files(check_all_files = False, diff_origin = False):
  """
  Args:
    check_all_files: True to run on all files, not just the git changes.
    diff_origin: git diff against origin/master, not HEAD.

  Returns:
    0 if linting completed without errors.
  """
  clang_format_binary = get_clang_format_binary()
  git_clang_format_py = get_git_clang_format_py()

  difftemp = '.difftemp.txt'
  return_code = 0

  # TODO(benvanik): multithreading.
  all_files = find_all_source_files()
  if check_all_files:
    print('- linting %d files' % (len(all_files)))
    any_errors = False
    for file_path in all_files:
      if os.path.exists(difftemp): os.remove(difftemp)
      ret = shell_call([
          clang_format_binary,
          '-output-replacements-xml',
          '-style=file',
          file_path,
          ], throw_on_error=False, stdout_path=difftemp)
      with open(difftemp) as f:
        had_errors = '<replacement ' in f.read()
      if os.path.exists(difftemp): os.remove(difftemp)
      if had_errors:
        any_errors = True
        print('')
        print(file_path)
        shell_call([
            clang_format_binary,
            '-style=file',
            file_path,
            ], throw_on_error=False, stdout_path=difftemp)
        diff = difflib.unified_diff(
            open(file_path).readlines(),
            open(difftemp).readlines())
        diff_str = ''.join(diff)
        print(diff_str)
        if os.path.exists(difftemp): os.remove(difftemp)
        print('')
    print('')
    if any_errors:
      print('ERROR: 1+ diffs. Stage changes and run \'xtool fix\' to fix.')
      return_code = 1
    else:
      print('Linting completed successfully.')
  else:
    print('- git-clang-format --diff')
    if os.path.exists(difftemp): os.remove(difftemp)
    ret = shell_call([
        'python',
        git_clang_format_py,
        '--binary=%s' % (clang_format_binary),
        '--commit=%s' % ('origin/master' if diff_origin else 'HEAD'),
        '--diff',
        ] + all_files, throw_on_error=False, stdout_path=difftemp)
    with open(difftemp) as f:
      contents = f.read()
      not_modified = 'no modified files' in contents
      not_modified = not_modified or 'did not modify' in contents
      f.close()
    if os.path.exists(difftemp): os.remove(difftemp)
    if not not_modified:
      any_errors = True
      print('')
      shell_call([
          'python',
          git_clang_format_py,
          '--binary=%s' % (clang_format_binary),
          '--commit=%s' % ('origin/master' if diff_origin else 'HEAD'),
          '--diff',
          ] + all_files)
      print('ERROR: 1+ diffs. Stage changes and run \'xtool fix\' to fix.')
      return_code = 1
    else:
      print('Linting completed successfully.')
  print('')

  return return_code


def lint_fix_files(check_all_files = False, diff_origin = False, force = False):
  """
  Args:
    check_all_files: True to run on all files, not just the git changes.
    diff_origin: git diff against origin/master, not HEAD.
    force: perform changes even if files are not staged.

  Returns:
    0 if linting completed without errors.
  """
  clang_format_binary = get_clang_format_binary()
  git_clang_format_py = get_git_clang_format_py()

  all_files = find_all_source_files()
  if check_all_files:
    print('- clang-format [%d files]' % (len(all_files)))
    any_errors = False
    for file_path in all_files:
      ret = shell_call([
          clang_format_binary,
          '-i',
          '-style=file',
          file_path,
          ], throw_on_error=False)
      if ret:
        any_errors = True
    print('')
    if any_errors:
      print('ERROR: 1+ clang-format calls failed.')
      print('Ensure all files are staged.')
      return 1
    else:
      print('Formatting completed successfully.')
      return 0
  else:
    print('- git-clang-format')
    shell_call([
        'python',
        git_clang_format_py,
        '--binary=%s' % (clang_format_binary),
        '--commit=%s' % ('origin/master' if diff_origin else 'HEAD'),
        ] + (['--force'] if force else []) + all_files)
    print('')
  return 0


def style_check_files(check_all_files = False, diff_origin = False):
  """
  Args:
    check_all_files: True to run on all files, not just the git changes.
    diff_origin: git diff against origin/master, not HEAD.

  Returns:
    0 if style check completed without errors.
  """
  # Select source files for style checking.
  all_files = find_all_source_files()
  source_files = []
  if check_all_files:
    source_files.extend(all_files)
  else:
    changed_files = find_changed_source_files(diff_origin = diff_origin)
    source_files.extend([changed_file for changed_file in changed_files
                         if changed_file in all_files])
  if not source_files:
    print('No source file changes found to style check')
    return 0

  # Remove _test.cc files.
  source_files = [source_file for source_file in source_files
                  if not source_file.endswith('_test.cc')]

  # Style guide check.
  # TODO(benvanik): eat the 'Done processing' lines when there are no errors.
  print('- cpplint [%d files]' % (len(source_files)))
  return_code = shell_call([
      'python',
      'third_party/google_styleguide/cpplint/cpplint.py',
      '--output=vs7',
      '--linelength=80',
      '--filter=-build/c++11,+build/include_alpha',
      '--root=xrtl/',
      ] + source_files, throw_on_error=False)
  print('')
  if return_code:
    print('ERROR: 1+ cpplint calls failed.')
  else:
    print('Style checking completed successfully.')
  return return_code


def buildifier_check_files(check_all_files = False, diff_origin = False,
                           fix = False):
  """
  Args:
    check_all_files: True to run on all files, not just the git changes.
    diff_origin: git diff against origin/master, not HEAD.
    fix: True to fix files in place.

  Returns:
    0 if buildifier check completed without errors.
  """
  # Select source files for style checking.
  buildifier_bin = get_bin('buildifier')
  if not buildifier_bin:
    print('ERROR: buildifier not found')
    return 1

  source_files = []
  if check_all_files:
    source_files = find_all_source_files(file_filter = is_bazel_file)
  else:
    source_files = find_changed_source_files(file_filter = is_bazel_file,
                                             diff_origin = diff_origin)
  if not source_files:
    print('No source file changes found to check with buildifier')
    return 0

  # Run buildifier.
  # NOTE: buildifier does not provide valid return codes, so we need to check
  #       the output to see if it changed anything.
  print('- buildifier [%d files]' % (len(source_files)))
  p = subprocess.Popen([
      get_bin('buildifier'),
      # '-path='  # TODO(benvanik): needed?
      '-mode=%s' % ('fix' if fix else 'check'),
      ] + source_files, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  (stdout, stderr) = p.communicate()
  print('')
  if len(stdout.strip()) > 0:
    print('ERROR: buildifier found one or more diffs:')
    print(stdout)
    return 1
  else:
    print('Buildifier checking completed successfully.')
    return 0


class LintCommand(Command):
  """'lint' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(LintCommand, self).__init__(
        subparsers,
        name='lint',
        help_short='Checks for lint and style errors with clang-format.',
        *args, **kwargs)
    if not self.parser: return
    self.parser.add_argument(
        '--all', action='store_true',
        help='Lint all files, not just those changed.')
    self.parser.add_argument(
        '--origin', action='store_true',
        help='Lints all files changed relative to origin/master.')

  def execute(self, args, pass_args, cwd):
    # We allow both tools to run even if the other fails.

    # lint.
    lint_return_code = lint_check_files(
        check_all_files = args['all'],
        diff_origin = args['origin'])

    # style check.
    style_return_code = style_check_files(
        check_all_files = args['all'],
        diff_origin = args['origin'])

    # buildifier check.
    buildifier_return_code = buildifier_check_files(
        check_all_files = args['all'],
        diff_origin = args['origin'])

    if lint_return_code:
      return lint_return_code
    if style_return_code:
      return style_return_code
    if buildifier_return_code:
      return buildifier_return_code

    return 0


class FixCommand(Command):
  """'fix' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(FixCommand, self).__init__(
        subparsers,
        name='fix',
        help_short='Reformats staged code with clang-format.',
        *args, **kwargs)
    if not self.parser: return
    self.parser.add_argument(
        '--all', action='store_true',
        help='Format all files, not just those changed.')
    self.parser.add_argument(
        '--origin', action='store_true',
        help='Formats all files changed relative to origin/master.')
    self.parser.add_argument(
        '-f', '--force', action='store_true',
        help='Apply changes even if files are not staged.')

  def execute(self, args, pass_args, cwd):
    # fix.
    lint_return_code = lint_fix_files(
        check_all_files = args['all'],
        diff_origin = args['origin'],
        force = args['force'])
    buildifier_return_code = buildifier_check_files(
        check_all_files = args['all'],
        diff_origin = args['origin'],
        fix = True)
    if lint_return_code:
      return lint_return_code
    if buildifier_return_code:
      return buildifier_return_code
    return 0


def generate_command_databases(config = default_config, output_base = None,
                               bazel_args = None):
  """
  Args:
    config: bazel --config= value used to generate the database.
            If none is provided the default for the host platform will be used.
    output_base: absolute path to dump bazel outputs.
    bazel_args: additional arguments to pass to the bazel command.

  Returns:
    0 if the databases were created successfully.
    Outputs will live at:
      `bazel-out/compile_commands.json`
      `bazel-out/link_commands.json`
  """
  # Get bazel-bin path for our configuration.
  build_root = os.path.dirname(bazel_info('bazel-bin', config = config,
                               output_base = output_base))
  execution_root = bazel_info('execution_root', config = config,
                              output_base = output_base)
  bazel_args = bazel_args if bazel_args else []

  # Remove all intermediate command files, as bazel won't clean them up for us.
  # There are probably good ways of avoiding this, but it's not so bad.
  compile_action_path = os.path.join(
      build_root, 'extra_actions', 'tools', 'actions',
      'generate_compile_commands_action')
  for root, dirnames, filenames in os.walk(compile_action_path):
    for filename in fnmatch.filter(filenames, '*_compile_command'):
      file_path = os.path.join(root, filename)
      os.chmod(file_path, 0777)
      os.remove(file_path)
  link_action_path = os.path.join(
      build_root, 'extra_actions', 'tools', 'actions',
      'generate_link_targets_action')
  for root, dirnames, filenames in os.walk(link_action_path):
    for filename in fnmatch.filter(filenames, '*_link_target'):
      file_path = os.path.join(root, filename)
      os.chmod(file_path, 0777)
      os.remove(file_path)

  # Perform a bazel clean, which is required to ensure we get headers. If bazel
  # doesn't build a target it won't have them in VS, which is lame.
  result = invoke_bazel('clean', [
      '--config=%s' % (config),
      ] + bazel_args,
      output_base = output_base)
  if result:
    print('Error performing clean before build with extra action')
    return result

  # Invoke bazel with the action listener and our build commands.
  # TODO(benvanik): multiple platforms, many roots, etc.
  result = invoke_bazel('build', [
      '--config=%s' % (config),
      '--experimental_action_listener',
      'tools/actions:generate_compile_commands_listener',
      '--experimental_action_listener',
      'tools/actions:generate_link_targets_listener',
      ] + bazel_args + top_level_packages,
      output_base = output_base)
  if result:
    print('Error performing build with extra action')
    return result

  # Combine all compile files into a single database.
  result = shell_call([
      'python',
      'tools/actions/generate_compile_commands_json.py',
      '--workspace_root=%s' % (self_path),
      '--execution_root=%s' % (execution_root),
      '--build_root=%s' % (build_root),
      '--output_file=%s' % (os.path.join('bazel-out', 'compile_commands.json')),
      ])
  if result:
    print('Error building compile command database')
    return result

  # Combine all link files into a single database.
  result = shell_call([
      'python',
      'tools/actions/generate_link_targets_json.py',
      '--workspace_root=%s' % (self_path),
      '--execution_root=%s' % (execution_root),
      '--build_root=%s' % (build_root),
      '--output_file=%s' % (os.path.join('bazel-out', 'link_targets.json')),
      ])
  if result:
    print('Error building link command database')
    return result

  return 0


def clang_tidy_files(check_all_files = False, diff_origin = False,
                     apply_fixes = False, output_base = None):
  """
  Args:
    check_all_files: True to run on all files, not just the git changes.
    diff_origin: git diff against origin/master, not HEAD.
    apply_fixes: automatically apply fixes suggested by clang-tidy.
    output_base: absolute path to dump bazel outputs.

  Returns:
    0 if tidy check completed without errors.
  """
  clang_tidy_binary = get_clang_tidy_binary()

  # TODO(benvanik): clang CROSSTOOL so we can generate the command database.
  if (sys.platform == 'cygwin' or sys.platform == 'win32'):
    print('ERROR: clang-tidy not supported on Windows!')
    print('https://github.com/google/xrtl/issues/2')
    return 0

  # Select source files.
  source_files = []
  if check_all_files:
    source_files = find_all_source_files()
  else:
    source_files = find_changed_source_files(diff_origin = diff_origin)

  # Remove _test.cc files.
  source_files = [source_file for source_file in source_files
                  if not source_file.endswith('_test.cc')]

  # Remove .h files. We could enable them independently with
  # INCLUDE_ALL_HEADERS in generate_compile_command.py.
  source_files = [source_file for source_file in source_files
                  if not source_file.endswith('.h')]

  # Avoid running if not needed.
  if not source_files:
    print('No source file changes found to tidy')
    return 0

  # Build a command database.
  result = generate_command_databases(output_base = output_base)
  if result:
    print('Error generating compile commands database')
    return result

  # Run clang-tidy.
  result = shell_call([
      clang_tidy_binary,
      '-p', 'bazel-out',
      '-style=file',
      '-checks=-*,google-*,clang-analyzer-*,misc-*,performance-*,-misc-unused-parameters',
      '-export-fixes=%s' % ('bazel-out/tidy_fixes.yaml'),
      ] + (['-fix'] if apply_fixes else []) + [
      ] + source_files)
  print('')
  if result:
    print('ERROR: 1+ clang-tidy errors. Use --fix to auto apply fixes.')
  else:
    print('clang-tidy checking completed successfully.')
  return result


class TidyCommand(Command):
  """'tidy' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(TidyCommand, self).__init__(
        subparsers,
        name='tidy',
        help_short='Runs the clang-tidy checker on all code.',
        *args, **kwargs)
    if not self.parser: return
    self.parser.add_argument(
        '--all', action='store_true',
        help='Format all files, not just those changed.')
    self.parser.add_argument(
        '--origin', action='store_true',
        help='Tidies all files changed relative to origin/master.')
    self.parser.add_argument(
        '--fix', action='store_true',
        help='Applies suggested fixes, where possible.')
    self.parser.add_argument(
        '--output_base',
        help='Write bazel outputs to the given path.')

  def execute(self, args, pass_args, cwd):
    # Tidy.
    return_code = clang_tidy_files(
        check_all_files = args['all'],
        diff_origin = args['origin'],
        apply_fixes = args['fix'],
        output_base = args['output_base'])
    return return_code


class PresubmitCommand(Command):
  """'presubmit' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(PresubmitCommand, self).__init__(
        subparsers,
        name='presubmit',
        help_short='Runs presubmit checks (lint/etc).',
        *args, **kwargs)
    if not self.parser: return
    self.parser.add_argument(
        '--fix', action='store_true',
        help='Applies suggested fixes, where possible.')
    self.parser.add_argument(
        '--keep_going', action='store_true',
        help='Prevents aborting on the first error.')

  def execute(self, args, pass_args, cwd):
    return_code = 0

    # Run fix first, as it will make lint pass if the issues were trivial.
    if args['fix']:
      return_code = lint_fix_files()
      if return_code and not args['keep_going']:
        print('Error running lint fix')
        return return_code
      return_code = clang_tidy_files(diff_origin = True, apply_fixes = True)
      if return_code and not args['keep_going']:
        print('Error running clang-tidy fix')
        return return_code

    # Run linter, which will error on anything fix could not fix or the style
    # checker finds.
    return_code = lint_check_files(diff_origin = True)
    if return_code and not args['keep_going']:
      print('Error running linter')
      return return_code
    return_code = style_check_files(diff_origin = True)
    if return_code and not args['keep_going']:
      print('Error running style checker')
      return return_code

    # Run clang-tidy.
    return_code = clang_tidy_files(diff_origin = True, apply_fixes = False)
    if return_code and not args['keep_going']:
      print('Error running clang-tidy')
      return return_code

    # TODO(benvanik): run tests.

    print('')
    if not return_code:
      print('Presubmit checks finished successfully')
    else:
      print('Presubmit checks failed! Do not commit!')

    return return_code


class GenerateSlnCommand(Command):
  """'sln' command."""

  def __init__(self, subparsers, *args, **kwargs):
    super(GenerateSlnCommand, self).__init__(
        subparsers,
        name='sln',
        help_short='Generates a Visual Studio sln file.',
        *args, **kwargs)
    if not self.parser: return

  def _extract_command_options(self, command):
    # Prepare command line.
    # - convert to ascii
    # - drop the msvc_cl.bat arg[0]
    command = command.decode('utf8')
    command = command[command.find(' ') + 1:]
    command = command.split(' ')
    command += ['/w']  # Turn off msvc_tools warnings

    defines = []
    include_paths = []
    for arg in command:
      if arg.startswith('/D') or arg.startswith('-D'):
        defines.append(arg[2:])
      elif arg.startswith('/I') or arg.startswith('-I'):
        include_paths.append(arg[2:].replace('/', '\\'))

    return (defines, include_paths)

  def execute(self, args, pass_args, cwd):
    # Generate a compile commands database.
    # This will let us get the defines used for all our files.
    return_code = generate_command_databases(config = 'windows_x86_64',
                                             bazel_args = pass_args)
    if return_code:
      print('Error generating compile commands')
      return return_code

    # This is what we have Visual Studio invoke for build/etc.
    xtool_path = '%s\\xtool.bat' % (convert_path_cygwin_to_win32(self_path))

    # Root where file paths will be in most cases.
    execution_root = bazel_info('execution_root', config = 'windows_x86_64')

    # Load template files.
    with open(os.path.join('tools', 'visual_studio', 'sln.template'),
              'r') as template_file:
      template_sln = string.Template(template_file.read())
    with open(os.path.join('tools', 'visual_studio', 'vcxproj.template'),
              'r') as template_file:
      template_vcxproj = string.Template(template_file.read())
    with open(os.path.join('tools', 'visual_studio',
                           'vcxproj.filters.template'), 'r') as template_file:
      template_filters = string.Template(template_file.read())
    with open(os.path.join('tools', 'visual_studio',
                           'vcxproj.user.template'), 'r') as template_file:
      template_user = string.Template(template_file.read())

    # Load the compile commands JSON.
    with open(os.path.join('bazel-out', 'compile_commands.json')) as json_file:
      compile_json_data = json.load(json_file, encoding='ascii')

    # Walk all commands in the database and extract their options.
    # We use each command to create a set of all defines and include paths used,
    # as the NMake project only allows global defines and paths.
    all_sources = []
    source_map = {}
    all_defines = []
    all_include_paths = []
    all_include_paths.append('.')
    all_include_paths.append(
        convert_path_cygwin_to_win32(os.path.abspath('.')) + os.sep)
    all_include_paths.append(
        convert_path_cygwin_to_win32(execution_root) + os.sep)
    for action_command in compile_json_data:
      # This may be a .cc or .h.
      source_file = action_command['file']
      source_path = os.path.join(action_command['directory'], source_file)
      # If the source path exists in the workspace root use that instead.
      workspace_source_file = source_file.replace(execution_root, '')
      if os.path.exists(workspace_source_file):
        source_path = os.path.abspath(workspace_source_file)
      source_map[source_path] = source_file
      # Extract CL command options.
      (defines, include_paths) = self._extract_command_options(
          action_command['command'])
      # Fix up include paths to be absolute.
      directory = action_command['directory'].replace('/', '\\')
      include_paths = ['%s\\%s' % (directory, include_path)
                       for include_path in include_paths]
      # Add to sets.
      if source_path not in all_sources:
        all_sources.append(source_path)
      for define in defines:
        if define not in all_defines:
          all_defines.append(define)
      for include_path in include_paths:
        include_path = convert_path_cygwin_to_win32(include_path) + os.sep
        if include_path not in all_include_paths:
          all_include_paths.append(include_path)

    # Load the link targets JSON.
    with open(os.path.join('bazel-out', 'link_targets.json')) as json_file:
      link_json_data = json.load(json_file, encoding='ascii')

    # Walk all link targets to find our projects.
    all_projects = []  # (name, uuid, exe path, vcxproj path)
    for link_target in link_json_data:
      # TODO(benvaniK): filter under //xrtl only?

      # Generate project info.
      # Note that the UUID must remain stable for each project so that VS tracks
      # them across updates properly.
      # Note also that executable is a full path to a particular config
      # (like fastbuild).
      target_package = link_target['package']
      target_uuid = format_uuid(link_target['uuid']).upper()
      target_executable = link_target['executable']
      target_executable = convert_path_cygwin_to_win32(target_executable)

      # Get package path and rule name.
      if ':' in target_package:
        # //foo:bar form.
        (package_path, rule_name) = target_package.split(':')
      else:
        # //foo/bar form.
        package_path = target_package
        rule_name = target_package[target_package.rfind('/') + 1:]
      if package_path.startswith('//'):
        package_path = package_path[2:]
      package_path = package_path.replace('/', os.sep)

      # TODO(benvanik): find only those files used by this package.
      #                 Could be done with a bazel query.
      used_sources = all_sources[:]

      # Make a path for the vcxproj.
      #   bazel-out/vs/..../package.vcxproj.
      vcxproj_path = os.path.join('.vs', package_path, rule_name + '.vcxproj')
      vcxproj_path = os.path.abspath(vcxproj_path)
      if not os.path.exists(os.path.dirname(vcxproj_path)):
        os.makedirs(os.path.dirname(vcxproj_path))

      all_projects.append((target_package, target_uuid,
                           target_executable,
                           convert_path_cygwin_to_win32(vcxproj_path)))

      # Generate the target.vcxproj.
      cl_compile_lines = []
      cl_include_lines = []
      for source_file in all_sources:
        source_file = convert_path_cygwin_to_win32(source_file)
        if source_file.endswith('.cc') or source_file.endswith('.c'):
          cl_compile_lines.append('<ClCompile Include="%s" />' % (source_file))
        else:
          cl_include_lines.append('<ClInclude Include="%s" />' % (source_file))
      vcxproj_file_contents = template_vcxproj.substitute({
          'XTOOL': xtool_path,
          'BAZEL_ARGS': ' '.join(pass_args),
          'TARGET_PACKAGE': target_package,
          'TARGET_UUID': target_uuid,
          'TARGET_EXE_DBG': target_executable.replace('-fastbuild', '-dbg'),
          'TARGET_EXE_FASTBUILD': target_executable,
          'TARGET_EXE_OPT': target_executable.replace('-fastbuild', '-opt'),
          'DEFINES': ';'.join(all_defines),
          'INCLUDE_PATHS': ';'.join(all_include_paths),
          'CL_COMPILE_LINES': '\n    '.join(cl_compile_lines),
          'CL_INCLUDE_LINES': '\n    '.join(cl_include_lines),
          })
      write_if_changed(vcxproj_path, vcxproj_file_contents)

      # Generate the target.vcxproj.filters.
      filter_paths = []  # foo\bar
      cl_compile_lines = []
      cl_include_lines = []
      for source_path in all_sources:
        # Get a filter name in the 'foo\bar' format rooted in our repository
        # root (like xrtl\base\foo.cc).
        source_file = source_map[source_path]
        filter_path = os.path.dirname(source_file)
        filter_path = filter_path.replace(self_path, '')
        if filter_path.startswith('/'):
          filter_path = filter_path[1:]
        filter_path = filter_path.replace('/', '\\')

        # Add filter for the path and all of its parents, if needed.
        parent_filter_path = filter_path
        while True:
          if not parent_filter_path:
            break
          if parent_filter_path not in filter_paths:
            filter_paths.append(parent_filter_path)
          else:
            break
          if '\\' not in parent_filter_path:
            break
          parent_filter_path = (
              parent_filter_path[0:parent_filter_path.rfind('\\')])

        source_path = convert_path_cygwin_to_win32(source_path)
        if source_path.endswith('.cc') or source_path.endswith('.c'):
          cl_compile_lines.append(
              ('<ClCompile Include="%s"><Filter>%s</Filter></ClCompile>' % (
                  source_path, filter_path)))
        else:
          cl_include_lines.append(
              ('<ClInclude Include="%s"><Filter>%s</Filter></ClInclude>' % (
                  source_path, filter_path)))
      filter_lines = []
      for filter_path in filter_paths:
        filter_uuid = format_uuid(str(hashlib.md5(filter_path).hexdigest()))
        filter_lines.append(
            ('<Filter Include="%s"><UniqueIdentifier>{%s}</UniqueIdentifier></Filter>') % (
                filter_path, filter_uuid.upper()))
      filters_file_contents = template_filters.substitute({
          'FILTER_LINES': '\n    '.join(filter_lines),
          'CL_COMPILE_LINES': '\n    '.join(cl_compile_lines),
          'CL_INCLUDE_LINES': '\n    '.join(cl_include_lines),
          })
      write_if_changed(vcxproj_path + '.filters', filters_file_contents)

      # Generate target.vcxproj.user, which contains debugging information.
      # We only do this if the file doesn't already exist so that we don't
      # overwrite information. User can bazel clean if they want new ones.
      user_file_contents = template_user.substitute()
      user_file_path = vcxproj_path + '.user'
      if not os.path.exists(user_file_path):
        with open(user_file_path, 'w') as file:
          file.write(user_file_contents)

    # Generate the sln with all projects and configurations.
    sln_path = os.path.join('.vs', 'xrtl.sln')
    sln_path = os.path.abspath(sln_path)
    if not os.path.exists(os.path.dirname(sln_path)):
      os.makedirs(os.path.dirname(sln_path))
    project_lines = []
    project_config_lines = []
    for (target_package, target_uuid, _, vcxproj_path) in all_projects:
      project_lines.append(
          ('Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "%s", "%s", "{%s}"' % (
              target_package, vcxproj_path, target_uuid)))
      for config in ('dbg', 'fastbuild', 'opt'):
        project_config_lines.append(('{%s}.%s|x64.ActiveCfg = %s|x64') % (
                                     target_uuid, config, config))
        project_config_lines.append(('{%s}.%s|x64.Build.0 = %s|x64') % (
                                     target_uuid, config, config))
    sln_file_contents = template_sln.substitute({
        'PROJECT_LINES': '\n'.join(project_lines),
        'PROJECT_CONFIG_LINES': '\n    '.join(project_config_lines),
        })
    write_if_changed(sln_path, sln_file_contents)

    print('')
    print('Visual Studio solution written to:')
    print('  %s' % (convert_path_cygwin_to_win32(sln_path)))
    print('NOTE: you may need to relaunch VS a few times to get intellisense')

    return return_code


if __name__ == '__main__':
  sys.exit(main())
